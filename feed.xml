<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://ginlov.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://ginlov.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-02-25T15:46:16+00:00</updated><id>https://ginlov.github.io/feed.xml</id><title type="html">Long-Giang Vu</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Variational Autoencoder explanation</title><link href="https://ginlov.github.io/blog/2022/vae/" rel="alternate" type="text/html" title="Variational Autoencoder explanation"/><published>2022-08-25T00:00:00+00:00</published><updated>2022-08-25T00:00:00+00:00</updated><id>https://ginlov.github.io/blog/2022/vae</id><content type="html" xml:base="https://ginlov.github.io/blog/2022/vae/"><![CDATA[<h2 id="likelihood-based-generative-models">Likelihood-based generative models</h2> <p>Generative Model is one of two model types in deep learning, which has the ability of generating data by sampling from the approximated distribution of data. That process requires the model to understand or have the ability to simulate the distribution of the given data. To do that, one straight forward approach is modeling the density function of data by a neural network \(p_{\theta}(x)\). That class of models called likelihood-based generative models. The objective is to maximize the likelihood function indexed by a set of paramters \(\theta\):</p> \[\begin{align*} \max_{\theta} \sum_{i} \log p_{\theta}(x^{(i)}) \end{align*}\] <p>The problem, from here, is to choose a proper architecture that can not only <strong>efficiently calculate the likelihood</strong> \(p_{\theta}(x)\) for training but also <strong>easily sample</strong> from. There are multiple ways to achieve that, such as autoregressive models <d-cite key="khajenezhad2020masked"></d-cite> <d-cite key="van2016pixel"></d-cite> <d-cite key="van2016conditional"></d-cite> <d-cite key="salimans2017pixelcnn++"></d-cite>, using an assumption of time-series data, or flow model <d-cite key="dinh2016density"></d-cite> <d-cite key="kingma2018glow"></d-cite> <d-cite key="ho2019flow++"></d-cite>. In this blog, we explore another approach which does not calculate exactly the likelihood but approximates it by an inferencing technique known as variational inference.</p> <hr/> <h2 id="latent-variable-models">Latent variable models</h2> <p>VAE <d-cite key="kingma2013auto"></d-cite> is inspired by latent variable models, which rely on an assumption about data - there is a compact representation of a data point in a lower-dimensional space. The representation is known as latent code. That means, again, one can encode a data set in the original space into a set of code in the latent space (look at the below image) while maintaining the properties of data distribution.</p> \[p_{\theta}(x) = \mathbb{E}_{z \sim p_{Z}} p_{\theta}(x\|z)\] <p>Technically, in case of descrete latent variable \(z\), \(p_{\theta}(x)\) can be transformed to \(\sum_{z}p_{Z}(z)p_{\theta}(x\|z)\). Unforturnately, in many real-world problems, \(z\) is continuous. Then, the challenge is calculating \(\int_{z}p_{Z}(z)p_{\theta}(x\|z)dz\). In that case, likelihood term \(p_{\theta}(x)\) can not be exactly calculated but approximated by some techniques. In next section, we will explore one of that techniques called variational inference.</p> <hr/> <h2 id="variational-inference-and-evidence-lower-bound">Variational inference and evidence lower bound</h2> <p>Applying Jensens inequality to the (above) log likelihood, we have the evidence lower bound: \(\begin{align*} \log{p_{\theta}(x^{(i)})} &amp;= \log \int_{z} p_{\theta}(x^{(i)}, z) dz \\ &amp;= \log \int_{z} p_{\theta}(x^{(i)}, z) \frac{q_{\phi}(z|x^{(i)})}{q_{\phi}(z|x^{(i)})} dz \\ &amp;= \log \mathbb{E}_{q_{\phi}(z|x^{(i)})} \frac{p_{\theta}(x^{(i)}, z)}{q_{\phi}(z|x^{(i)})} \\ &amp;\geq \mathbb{E}_{q_{\phi}(z|x^{(i)})} \log \left[ \frac{p_{\theta}(x^{(i)}, z)}{q_{\phi}(z)} \right] \textnormal{(Jensen inequality)}\\ &amp;= \mathbb{E}_{q_{\phi}(z|x^{(i)})} \left[\log p_{\theta}(x^{(i)}, z) - \log q_{\phi}(z | x^{(i)}) \right]\\ &amp;= \mathcal{L}(\theta, \phi, x^{(i)}) \end{align*}\)</p> <p>Where \(q_{\phi}(z)\) is called recognition model and \(\mathcal{L}(\theta, \phi, x^{(i)})\) is called evidence lower bound of the log likelihood function. To calculate ELBO, it is essential to reckon the expectation over recognition distribution. Prior approaches, such as Monte Carlo sampling \(\mathbb{E}_{q_{\phi}}[f(z)] \approx \frac{1}{K} \sum_{i=1}^{K} f(z^{(i)})\) is high variance which leads to unreasonable result. In the next section, a reparameterization trick is introduced to solve this problem.</p> <hr/> <h2 id="reparameterization-trick">Reparameterization trick</h2> <p>With \(z\) is a random variable, and \(z \sim q_{\phi}(z|x)\), it is possible to express \(z\) as a deterministic variable \(z=g_{\phi}(\epsilon, x)\), where \(\epsilon\) is an auxiliary variable with independent marginal \(p(\epsilon)\).</p> <p>For example, assume that \(z \sim q_{\phi}(z, x) = \mathcal{N}(\mu, \sigma^{2})\). \(z\) can be expressed as \(z=\mu + \sigma \epsilon\) where \(\epsilon \sim \mathcal{N}(\mathbf{0}, \mathbf{I})\).</p> <p>Using above trick, the ELBO can be re-written as:</p> \[\begin{align*} \mathcal{L}(\theta, \phi, x^{(i)}) &amp;= \mathbb{E}_{q_{\phi}(z|x^{(i)})} \left[\log p_{\theta}(x^{(i)}, z) - \log q_{\phi}(z | x^{(i)}) \right]\\ &amp;= \frac{1}{L} \sum_{l=1}^{L} \left[ \log p_{\theta}(x^{(i)}, g_{\phi}(x^{(i)}, \epsilon^{(l)})) - \log q_{\phi}(g_{\phi}(x^{(i)}, \epsilon^{(l)}) | x^{(i)})\right] \end{align*}\] <p>Where \(\epsilon^{(l)} \sim p(\epsilon)\). Since \(p(\epsilon)\) is independent, sampling is now easy with low variance. From here, optimizing ELBO is as normal as optimizing other loss function using gradient descent. In the next section, another perspective of this loss function is investigated and illustrated the connection to auto-encoder.</p> <hr/> <h2 id="connection-to-auto-encoder">Connection to auto-encoder</h2> <p>Further transforming the evidence lower bound give us another view of this loss function:</p> \[\begin{align*} \mathcal{L}(\theta, \phi, x^{(i)}) &amp;= \mathbb{E}_{q_{\phi}(z|x^{(i)})} \left[\log p_{\theta}(x^{(i)}, z) - \log q_{\phi}(z | x^{(i)}) \right]\\ &amp;= \mathbb{E}_{q_{\phi}(z|x^{(i)})} \left[\log p_{\theta}(x^{(i)} | z) + \log p_{\theta}(z) - \log q_{\phi}(z | x^{(i)}) \right]\\ &amp;= \mathbb{E}_{q_{\phi}(z|x^{(i)})} \log p_{\theta}(x^{(i)}|z) - \mathbb{E}_{q_{\phi}(z|x^{(i)})} \log \frac{q_{\phi}(z | x^{(i)})}{p_{\theta}(z)} \\ &amp;= \mathbb{E}_{q_{\phi}(z|x^{(i)})} \log p_{\theta}(x^{(i)}|z) - \mathrm{D}_{KL}(q_{\phi}(z|x^{(i)}) || p_{\theta}(z)) \end{align*}\] <p>The first term is the reconstruction loss and the second term can be thought as a regularization term. Because of that, this model can be thought as the variational auto-encoder.</p> <p>Optimizing loss function using this view is similar to the mentioned above method.</p> <hr/> <h2 id="conclusion">Conclusion</h2> <p>Auto-encoding Variational Bayes introduced the recognition model \(q_{\phi}(z|x)\) to approximate the true posterior \(p_{\theta}(z|x)\) which is intractable in general case. In addition, to efficiently calculate the loss term, AVB also proposed a reparameterization trick which allow sampling from recognition model \(q_{\phi}(z|x)\) easily with low variance.</p>]]></content><author><name>Long Giang Vu</name></author><category term="Generative Model"/><category term="VAE"/><summary type="html"><![CDATA[Explanation of VAE.]]></summary></entry><entry><title type="html">Denoising Diffusion Probabilistic Model explanation</title><link href="https://ginlov.github.io/blog/2022/diffusion/" rel="alternate" type="text/html" title="Denoising Diffusion Probabilistic Model explanation"/><published>2022-06-24T00:00:00+00:00</published><updated>2022-06-24T00:00:00+00:00</updated><id>https://ginlov.github.io/blog/2022/diffusion</id><content type="html" xml:base="https://ginlov.github.io/blog/2022/diffusion/"><![CDATA[<h2 id="problem-formulation">Problem formulation</h2> <p>In recent years, Generative Adversarial Network has dominated the field of the generative model in terms of sample quality and inference rate. Yet GANs show the weakness in the data distribution coverage and the challenging problem of training. In 2015, the idea of diffusion model <d-cite key="sohl2015deep"></d-cite> came out and then in 2020, DDPM <d-cite key="ho2020denoising"></d-cite> was introduced and illustrated amazing results regarding image fidelity and the coverage of distribution. Furthermore, in 2021, Dhariwal and Nichol <d-cite key="dhariwal2021diffusion"></d-cite> showed that Diffusion Models have the ability to overcome GANs in the sample quality and exhibit good behavior in distribution coverage, which is the critical weakness of GANs.</p> <p>In this blog, we will go through the idea and derivation of diffusion models (the formulas and ideas follow DDPM <d-cite key="ho2020denoising"></d-cite>).</p> <div class="l-body"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/diffusion/figure1-480.webp 480w,/assets/img/posts/diffusion/figure1-800.webp 800w,/assets/img/posts/diffusion/figure1-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/diffusion/figure1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="diffusion visualization" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>The concept of diffusion model is diffusing the original image into a white noise by a given strategy and then learning a reverse process to approximate it. Behind the scene, for both Gaussian and binomial diffusion, <d-cite key="feller1949theory"></d-cite> shows that if the noise schedule at each step is small enough, the reverse process shares the same form as the forward one, which is a vital factor that guides the way of constructing the loss functions and the learning algorithms.</p> <p>In detail, forward process is formulated as follow:</p> \[\begin{align*} q(x_{1:T}|x_{0}) = q(x_{0}).\prod^{T}_{1} q(x_{t}|x_{t-1}) \\ q(x_{t}|x_{t-1}) = \mathcal{N}(\sqrt{1-\beta_{t}}\:x_{t-1}, \beta_{t}\mathrm{I}) \end{align*}\] <p>where \(\beta_{t}\) is the noise schedule which is added to image sample, \(T\) is the number of diffusion steps. In particular, Ho <d-cite key="ho2020denoising"></d-cite> models the forward process as a Markov chain, in which the random variable \(x_{t}\) only depends on the right previous one \(x_{t-1}\).</p> <p>The reverse process is the reversal version of the forward procedure:</p> \[\begin{align*} p_{\theta}(x_{0:T}) = p(x_{T}).\prod^{T}_{1} p_{\theta}(x_{t-1}|x_{t}) \\ p(x_{T}) = \mathcal{N}(\mathrm{0}, \mathrm{I}) \end{align*}\] <p>The task is now searching for the proper form of \(p_{\theta}\), constructing the loss function and the learning algorithm.</p> <p>To make the later notation more readable, some transformations are made to the formulation as follows:</p> <p>Set \(\alpha_{t} = 1 - \beta_{t}\) and \(\bar{\alpha}_{t} = \prod_{s=1}^{T} \alpha_{s}\), \(q(x_{t}\vert x_{t-1})\) can be rewritten as follow:</p> \[\begin{align*} q(x_{t}|x_{t-1}) = \mathcal{N}(\sqrt{\alpha_{t}}\:x_{t-1}, (1-\alpha_{t})\mathrm{I}) \end{align*}\] <p>Using above notation reveals a nice ability of sampling \(x_{t}\) with a trivial effort:</p> \[\begin{align*} x_{t} &amp;= \sqrt{\alpha_{t}}\:x_{t-1} + \sqrt{(1-\alpha_{t})} z_{t} \\ &amp;= \sqrt{\alpha_{t}}\: (\sqrt{\alpha_{t-1}}\:x_{t-2} + \sqrt{(1-\alpha_{t-1})} z_{t-1}) + \sqrt{(1-\alpha_{t})} z_{t} \\ &amp;= \sqrt{\alpha_{t}\alpha_{t-1}}\: x_{t-2} + \sqrt{\alpha_{t}(1-\alpha_{t-1})} z_{t-1} + \sqrt{(1-\alpha_{t})} z_{t} \end{align*}\] <p>Where \(z_{t}\) and \(z_{t-1}\) is random variable sampled from standard normal distribution \(\mathcal{N}(\mathrm{0}, \mathrm{I})\). So let think the whole \(\sqrt{\alpha_{t}(1-\alpha_{t-1})} z_{t-1} + \sqrt{(1-\alpha_{t})} z_{t}\) term as a random variable, which is combined of two smaller term: \(\sqrt{\alpha_{t}(1-\alpha_{t-1})} z_{t-1}\) follows \(\mathcal{N}(\mathrm{0}, \alpha_{t}(1-\alpha_{t-1}) \mathrm{I})\) and \(\sqrt{(1-\alpha_{t})} z_{t}\) follows \(\mathcal{N}(\mathrm{0}, (1-\alpha_{t}) \mathrm{I})\). Because two terms \(\sqrt{\alpha_{t}(1-\alpha_{t-1})} z_{t-1}\) and \(\sqrt{(1-\alpha_{t})} z_{t}\) are independent, so the whole term \(\sqrt{\alpha_{t}(1-\alpha_{t-1})} z_{t-1} + \sqrt{(1-\alpha_{t})} z_{t}\) follows \(\mathcal{N}(\mathrm{0}, (1-\alpha_{t-1}\alpha_{t}) \mathrm{I})\). Thus, we have:</p> \[\begin{align*} x_{t} &amp;= \sqrt{\alpha_{t}\alpha_{t-1}}\: x_{t-2} + \sqrt{(1-\alpha_{t-1}\alpha_{t})} \bar{z}_{t} \end{align*}\] <p>Where \(\bar{z}_{t}\) is random variable sampled from standard normal distribution. Do above transformation repeatly, \(x_{t}\) becomes:</p> \[\begin{align*} x_{t} &amp;= \sqrt{\prod_{s=1}^{T} \alpha_{s}}\: x_{0} + \sqrt{(1-\prod_{s=1}^{T} \alpha_{s})} \bar{z}_{t} \\ &amp;= \sqrt{\bar{\alpha}_{t}}\: x_{0} + \sqrt{(1-\bar{\alpha}_{t})} \bar{z}_{t} \end{align*}\] <p>Finally, the marginal distribution is well-defined \(q(x_{t}\vert x_{0}) = \mathcal{N}(\sqrt{\bar{\alpha}_{t}}\: x_{0}, (1-\bar{\alpha}_{t})\mathrm{I})\), which allows us to sample an arbitrary \(x_{t}\) from \(x_{0}\).</p> <hr/> <h2 id="loss-function-construction">Loss function construction</h2> <p>The target is maximizing the likelihood of real data under the reverse distribution. To do so, training is minimizing the lower bound of the negative log-likelihood: <d-footnote>If you are confused by the lower bound, read the blog about VAE <d-cite key="vaetheory"></d-cite>.</d-footnote></p> \[\begin{align*} \mathbf{E}[-\log p_{\theta}(x_{0})] \leq \mathbf{E}_{q} \left[ -\log\frac{p_{\theta}(x_{0:T})}{q(x_{1:T}|x_{0})} \right] \end{align*}\] <p>The loss function can be derived as follow:</p> \[\begin{align*} \mathbf{E}_{q} \left[ -\log\frac{p_{\theta}(x_{0:T})}{q(x_{1:T}|x_{0})} \right] &amp;=\mathbf{E}_{q}\left[-\log{\frac{p(x_{T}).\prod^{T}_{1} p_{\theta}(x_{t-1}|x_{t})}{q(x_{1:T}|x_{0})}}\right] \\ &amp;=\mathbf{E}_{q}\left[ -\log{p(x_{T})} - \sum_{t\geq1} \log \frac{p_{\theta}(x_{t-1}|x_{t})}{q(x_{t}|x_{t-1})} \right] \\ &amp;=\mathbf{E}_{q}\left[ -\log{p(x_{T})} - \sum_{t&gt;1} \log \frac{p_{\theta}(x_{t-1}|x_{t})}{q(x_{t}|x_{t-1})} - \log(\frac{p_{\theta}(x_{0}|x_{1})}{q(x_{1}|x_{0})})\right] \\ &amp;=\mathbf{E}_{q}\left[ -\log{p(x_{T})} - \sum_{t&gt;1} \log \frac{p_{\theta}(x_{t-1}|x_{t})}{q(x_{t-1}|x_{t}, x_{0})}.\frac{q(x_{t-1}|x_{0})}{q(x_{t}|x_{0})} - \log(\frac{p_{\theta}(x_{0}|x_{1})}{q(x_{1}|x_{0})})\right] \\ &amp;=\mathbf{E}_{q}\left[ -\log{p(x_{T})} - \sum_{t&gt;1} \log \frac{p_{\theta}(x_{t-1}|x_{t})}{q(x_{t-1}|x_{t}, x_{0})} -\sum_{t&gt;1}\log\frac{q(x_{t-1}|x_{0})}{q(x_{t}|x_{0})} - \log(\frac{p_{\theta}(x_{0}|x_{1})}{q(x_{1}|x_{0})})\right] \\ &amp;=\mathbf{E}_{q}\left[ -\log{p(x_{T})} - \sum_{t&gt;1} \log \frac{p_{\theta}(x_{t-1}|x_{t})}{q(x_{t-1}|x_{t}, x_{0})} - \log\frac{1}{q(x_{T}|x_{0})} - \log(\frac{p_{\theta}(x_{0}|x_{1})}{q(x_{1}|x_{0})})\right] \\ &amp;=\mathbf{E}_{q}\left[ -\log\frac{p(x_{T})}{q(x_{T}|x_{0})} - \sum_{t&gt;1} \log \frac{p_{\theta}(x_{t-1}|x_{t})}{q(x_{t-1}|x_{t}, x_{0})} - \log(\frac{p_{\theta}(x_{0}|x_{1})}{q(x_{1}|x_{0})})\right] \\ \end{align*}\] <p>Let \(L_{t} = \mathbf{E}_{q}\left[- \log \frac{p_{\theta}(x_{t-1} \vert x_{t})}{q(x_{t-1}\vert x_{t}, x_{0})} \right]\) as an example.</p> \[\begin{align*} \mathbf{E}_{q}\left[- \log \frac{p_{\theta}(x_{t-1}|x_{t})}{q(x_{t-1}|x_{t}, x_{0})} \right] &amp;= \int q(x_{0:T})\log \frac{q(x_{t-1}|x_{t}, x_{0})}{p_{\theta}(x_{t-1}|x_{t})} dx_{0:T} \\ &amp;= \int q(x_{t-1}|x_{t}, x_{0}) q(x_{t}, x_{0}) q(x_{1:t-2}, x_{t+1:T}|x_{0}, x_{t-1}, x_{t}) \log \frac{q(x_{t-1}|x_{t}, x_{0})}{p_{\theta}(x_{t-1}|x_{t})} dx_{0:T} \\ &amp;= \int \left[ \int q(x_{t-1}|x_{t}, x_{0}) \log \frac{q(x_{t-1}|x_{t}, x_{0})}{p_{\theta}(x_{t-1}|x_{t})} dx_{t-1}\right] q(x_{0:t-2}, x_{t:T}|x_{t-1}) dx_{0:t-2, t:T} \\ &amp;= \int [\mathrm{D}_{\mathrm{KL}}(q(x_{t-1}| x_{0}, x_{t}) || p_{\theta}(x_{t-1}|x_{t}))]\: q(x_{0:t-2}, x_{t:T}|x_{t-1}) dx_{0:t-2, t:T} \\ &amp;= \mathbf{E}_{q(x_{0:t-2}, x_{t:T}|x_{t-1})} [\mathrm{D}_{\mathrm{KL}}(q(x_{t-1}| x_{0}, x_{t}) || p_{\theta}(x_{t-1}|x_{t}))] \end{align*}\] <p>One noticeable property is that with given \(x_{t-1}, x_{0}\), \(q(x_{t-1}\vert x_{0}, x_{t})\) and \(p_{\theta}(x_{t-1}\vert x_{t})\) are completely defined and \(\mathrm{D}_{\mathrm{KL}}(q(x_{t-1}\vert x_{0}, x_{t}) \| p_{\theta}(x_{t-1}\vert x_{t}))\) is known, or can be set as a constant. Thus, above formula is equal to:</p> \[\begin{align*} \mathbf{E}_{q(x_{t-1})} [\mathrm{D}_{\mathrm{KL}}(q(x_{t-1}| x_{0}, x_{t}) || p_{\theta}(x_{t-1}|x_{t}))] = \mathrm{D}_{\mathrm{KL}}(q(x_{t-1}| x_{0}, x_{t}) || p_{\theta}(x_{t-1}|x_{t})) \end{align*}\] <p>From that observation, \(L_{t}\) has the form as below:</p> \[\begin{align*} \mathbf{E}_{q}\left[- \log \frac{p_{\theta}(x_{t-1}|x_{t})}{q(x_{t-1}|x_{t}, x_{0})} \right] &amp;= \mathbf{E}_{q(x_{0:t-2}, x_{t:T}|x_{t-1})} [\mathrm{D}_{\mathrm{KL}}(q(x_{t-1}| x_{0}, x_{t}) || p_{\theta}(x_{t-1}|x_{t}))] \\ &amp;= \mathbf{E}_{q(x_{0:t-2}, x_{t:T}|x_{t-1})} \mathbf{E}_{q(x_{t-1})} [\mathrm{D}_{\mathrm{KL}}(q(x_{t-1}| x_{0}, x_{t}) || p_{\theta}(x_{t-1}|x_{t}))] \\ &amp;= \mathbf{E}_{q(x_{0:T})}[\mathrm{D}_{\mathrm{KL}}(q(x_{t-1}| x_{0}, x_{t}) || p_{\theta}(x_{t-1}|x_{t}))] \end{align*}\] <p>Applying above transformation to the general \(L\):</p> \[\begin{align*} L &amp;=\mathbf{E}_{q}\left[-\log{\frac{p_{\theta}(x_{0:T})}{q(x_{1:T}|x_{0})}}\right] \\ &amp;=\mathbf{E}_{q}\left[ \mathrm{D}_{\mathrm{KL}}(q(x_{T}|x_{0})||\:p(x_{T})) + \sum_{t&gt;1}\mathrm{D}_{\mathrm{KL}}(q(x_{t-1}|x_{t}, x_{0}) ||\: p_{\theta}(x_{t-1}|x_{t})) + \log(\frac{q(x_{1}|x_{0})}{p_{\theta}(x_{0}|x_{1})})\right] \end{align*}\] <p>Since the term \(\mathrm{D}_{\mathrm{KL}}(q(x_{T} \vert x_{0}) \vert\:p(x_{T}))\) is a constant, training is now approximating the reverse distribution \(p_{\theta}(x_{t-1}\vert x_{t})\) to the posterior \(q(x_{t-1}\vert x_{t}, x_{0})\).</p> <hr/> <h2 id="posterior-distribution">Posterior distribution</h2> <p>In the above section, we have gone through the ideas and transformations for the loss function. Noticeablly, the loss function is cumulative of KL divergence between the reverse distribution and the posterior over all timestep \(t\). To complete the loss function transformation, letâ€™s take a glance at the posterior <d-cite key="weng2021diffusion"></d-cite>.</p> \[\begin{align*} q(x_{t-1}|x{t}, x_{0}) &amp;= \frac{q(x_{t}, x_{t-1}|x_{0})}{q(x_{t}|x_{0})} \\ &amp;= q(x_{t}|x_{t-1}, x_{0})\frac{q(x_{t-1}|x_{0})}{q(x_{t}|x_{0})} \\ &amp;= q(x_{t}|x_{t-1})\frac{q(x_{t-1}|x_{0})}{q(x_{t}|x_{0})} \\ &amp;\propto \text{exp} \left(- \frac{1}{2}(\frac{(x_{t} - \sqrt{\alpha_{t}}\,x_{t-1})^{2}}{\beta_{t}} + \frac{(x_{t-1}-\sqrt{\bar{\alpha}_{t-1}}\,x_{0})^2}{1 - \bar{\alpha}_{t-1}} - \frac{(x_{t}-\sqrt{\bar{\alpha}_{t}}x_{0})^2}{1-\bar{\alpha}_{t}})\right) \\ &amp;= \text{exp} \left(- \frac{1}{2} ((\frac{\alpha_{t}}{\beta_{t}} + \frac{1}{1-\bar{\alpha}_{t-1}})x^{2}_{t-1} - (\frac{2\sqrt{\alpha_{t}}}{\beta_{t}}x_{t} + \frac{2\sqrt{\bar{\alpha}_{t-1}}}{1-\bar{\alpha}_{t-1}}x_{0})x_{t-1} + \mathbf{C}(x_{t}, x_{0}))\right) \end{align*}\] <p>Consider the equation inside.</p> \[\begin{align*} &amp;\ (\frac{\alpha_{t}}{\beta_{t}} + \frac{1}{1-\bar{\alpha}_{t-1}})x^{2}_{t-1} - (\frac{2\sqrt{\alpha_{t}}}{\beta_{t}}x_{t} + \frac{2\sqrt{\bar{\alpha}_{t-1}}}{1-\bar{\alpha}_{t-1}}x_{0})x_{t-1} + \mathbf{C}(x_{t}, x_{0}) \\ &amp;= (\frac{\alpha_{t}(1-\bar{\alpha}_{t-1}) + \beta_{t}}{\beta_{t}(1-\bar{\alpha}_{t-1})})\,x_{t-1}^2 - 2(\frac{\sqrt{\alpha_{t}}(1-\bar{\alpha}_{t-1})x_{t} + \sqrt{\bar{\alpha}_{t-1}}\beta_{t}x_{0}}{\beta_{t}(1-\bar{\alpha}_{t-1})})x_{t-1} + \mathbf{C}(x_{t}, x_{0}) \\ &amp;=\frac{\alpha_{t}-\alpha_{t}\bar{\alpha}_{t-1} + 1 - \alpha_{t}}{\beta_{t}(1-\bar{\alpha}_{t-1})}x_{t-1}^2 - 2(\frac{\sqrt{\alpha_{t}}(1-\bar{\alpha}_{t-1})}{\beta_{t}(1-\bar{\alpha}_{t-1})}x_{t} + \frac{\sqrt{\bar{\alpha}_{t-1}}\beta_{t}}{\beta_{t}(1-\bar{\alpha}_{t-1})}x_{0})x_{t-1} + \mathbf{C}(x_{t}, x_{0}) \\ &amp;=\frac{1 - \bar{\alpha}_{t}}{\beta_{t}(1-\bar{\alpha}_{t-1})}x_{t-1}^2 - 2(\frac{\sqrt{\alpha_{t}}(1-\bar{\alpha}_{t-1})}{\beta_{t}(1-\bar{\alpha}_{t-1})}x_{t} + \frac{\sqrt{\bar{\alpha}_{t-1}}\beta_{t}}{\beta_{t}(1-\bar{\alpha}_{t-1})}x_{0})x_{t-1} + \mathbf{C}(x_{t}, x_{0}) \\ &amp;=\frac{1 - \bar{\alpha}_{t}}{\beta_{t}(1-\bar{\alpha}_{t-1})}\left( x_{t-1}^2 - 2(\frac{\sqrt{\alpha_{t}}(1-\bar{\alpha}_{t-1})}{1 - \bar{\alpha}_{t}}x_{t} + \frac{\sqrt{\bar{\alpha}_{t-1}}\beta_{t}}{1 - \bar{\alpha}_{t}}x_{0})x_{t-1}\right) + \mathbf{C}(x_{t}, x_{0}) \end{align*}\] <p>From here \(q(x_{t-1}\vert x{t}, x_{0})\) can be seen as a Gaussian with \(\mathbf{E}_{q(x_{t-1}\vert x_{t},x_{0})}[x_{t-1}] = \frac{\sqrt{\alpha_{t}}(1-\bar{\alpha}_{t-1})}{1 - \bar{\alpha}_{t}}x_{t} + \frac{\sqrt{\bar{\alpha}_{t-1}}\beta_{t}}{1 - \bar{\alpha}_{t}}x_{0}\) and \({\mathbf{V}_{q(x_{t-1} \vert x_{t},x_{0})}[x_{t-1}] = \frac{\beta_{t}(1-\bar{\alpha}_{t-1})}{1 - \bar{\alpha}_{t}}}\).</p> <p>Denote \(\tilde{\mu}_{t} = \frac{\sqrt{\alpha_{t}}(1-\bar{\alpha}_{t-1})}{1 - \bar{\alpha}_{t}}x_{t} + \frac{\sqrt{\bar{\alpha}_{t-1}}\beta_{t}}{1 - \bar{\alpha}_{t}}x_{0}\) and \(\tilde{\beta}_{t} = \frac{\beta_{t}(1-\bar{\alpha}_{t-1})}{1 - \bar{\alpha}_{t}}\), then we have \(q(x_{t-1}\vert x_{t}, x_{0}) = \mathcal{N}(\tilde{\mu}_{t}, \tilde{\beta}_{t}\mathrm{I})\). Furthermore, we have \(x_{t} = \sqrt{\bar{\alpha}_t} x_{0} + \sqrt{(1-\bar{\alpha}_{t})}\epsilon\):</p> \[\begin{align*} \tilde{\mu}_{t} &amp;= \frac{\sqrt{\alpha_{t}}(1-\bar{\alpha}_{t-1})}{1 - \bar{\alpha}_{t}}x_{t} + \frac{\sqrt{\bar{\alpha}_{t-1}}\beta_{t}}{1 - \bar{\alpha}_{t}}x_{0} \\ &amp;= \frac{\sqrt{\alpha_{t}}(1-\bar{\alpha}_{t-1})}{1 - \bar{\alpha}_{t}}x_{t} + \frac{\sqrt{\bar{\alpha}_{t-1}}\beta_{t}}{1 - \bar{\alpha}_{t}} \left( \frac{x_{t} - \sqrt{(1-\bar{\alpha}_{t})}\epsilon}{\sqrt{\bar{\alpha}_t}}\right) \\ &amp;= \gamma_{t}x_{t} + \frac{\beta_{t}}{\sqrt{\alpha_{t}(1-\bar{\alpha}_{t})}} \epsilon \end{align*}\] <hr/> <h2 id="parameterizing-the-reverse-distribution">Parameterizing the reverse distribution</h2> <p>Because posterior distribution is gaussian, it is reasonable to construct reverse distribution as a gaussian one \(p_{\theta}(x_{t-1} \vert x_{t}) = \mathcal{N}(\mu_{\theta}(x_{t}, t), \Sigma_{\theta}(x_{t}, t))\). According to Ho <d-cite key="ho2020denoising"></d-cite>, fixed \(\Sigma_{\theta}\) illustrates better results than trainable one. In detail, the authors use two options to fix \(\Sigma_{\theta}\):</p> <ul> <li>Fix to noise schedule: \(\Sigma_{\theta} = \beta_{t}\mathrm{I}\)</li> <li>Fix to posterior variance: \(\Sigma_{\theta} = \tilde{\beta}_{t}\mathrm{I}\)</li> </ul> <p>Since \(\Sigma_{\theta}\) is fix, KL divergence at timestep \(t\) has close form:</p> \[\begin{align*} L_{t-1} &amp;= \mathbf{E}_{q}(\mathrm{D}_{\mathrm{KL}}(q(x_{t-1}|x_{t}, x_{0}) ||\: p_{\theta}(x_{t-1}|x_{t}))) \\ &amp;= \mathbf{E}_{q}\left[ \frac{\beta_{t}^{2}}{2\sigma_{t}^{2}\alpha_{t}(1-\bar{\alpha}_{t})} || \epsilon - \epsilon_{\theta}(x_{t}, t)||^{2} \right] \end{align*}\] <p>From here, one can calculate the loss function easily and train the network. Below is the algorithm Ho <d-cite key="ho2020denoising"> </d-cite> used for his training.</p> <div class="l-body"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/diffusion/figure2-480.webp 480w,/assets/img/posts/diffusion/figure2-800.webp 800w,/assets/img/posts/diffusion/figure2-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/diffusion/figure2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="algorithms" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <hr/> <h2 id="conclusion">Conclusion</h2> <ol> <li> <p>Pros:</p> <ul> <li>Diffusion model shows a new method to generate data with high quality.</li> <li>Data generated using this family of models avoid mode collapse, which leads to a higher number in likelihood score.</li> </ul> </li> <li> <p>Cons:</p> <ul> <li>Because of the idea of gradually denoise from initial datapoint, diffusion model requires large number step to generate a sample, which is less efficient that prior method such as GANs or VAE.</li> </ul> </li> <li> <p>Further work:</p> <ul> <li>There are numerous works pushing efforts in accelerating inference rate of diffusion models such as Nicol <d-cite key="nichol2021improved"></d-cite>, Song <d-cite key="song2020denoising"></d-cite>. Inspite of large efforts on improving sampling speed, all methods succeeding in it show a trade-off between speed and quality of generated images.</li> <li>Song <d-cite key="song2020score"></d-cite> proposes a statistical framework to explain diffusion models, with which, one has several options to construct new diffusion models. The authors also propose a method for boosting sampling speed while preserving image quality.</li> </ul> </li> </ol>]]></content><author><name>Long Giang Vu</name></author><category term="Generative Model"/><category term="Diffusion"/><summary type="html"><![CDATA[Explanation of DDPM.]]></summary></entry></feed>